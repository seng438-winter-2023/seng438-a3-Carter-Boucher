**SENG 438 - Software Testing, Reliability, and Quality**

**Lab. Report #3 – Code Coverage, Adequacy Criteria and Test Case Correlation**

| Group \#:      | 11    |
| -------------- | --- |
| Student Names: | Carter Boucher    |
|                | Ayo Olabode    |
|                | Maheen Hossain   |
|                | Jason Wu    |

# 1 Introduction

The primary aim of this laboratory is to familiarize individuals with the principles of white box testing through the utilization of the JUnit framework and coverage tools, which aid in generating a comprehensive code coverage for our test suite. Furthermore, applying white box testing ensures that our unit tests are validated at the unit testing level. The coverage tools utilized in this lab also assist in identifying the extent to which our unit testing has been executed through our created tests, as well as how much remains. White box testing permits us to conduct a more rigorous and comprehensive testing phase of the software development cycle by assessing all feasible code pathways.

# 2 Manual data-flow coverage calculations for X and Y methods

Text…

# 3 A detailed description of the testing strategy for the new unit test

For our new unit tests, we designed test cases using white-box testing because we have access to the class directly. We are able to see the code and design unit tests based off of the code structure directly. Our testing strategy was to design test cases to increase instruction coverage, branch coverage, and method coverage. We designed test cases based on knowledge of the code structure using coverage-tools and each test case was designed to increase coverage of at-least one category. We started with method-coverage to make sure that each method was covered and then instruction-coverage to make sure as many lines of code were utilized and tested as possible. To finish off our testing strategy, we went back through the methods and covered each possible branch found to increase branch-coverage.

__Coverage Before__

Range.java (Maheen and Jason)
- Instructions: 44.4%
- Branch: 52.6%
- Method: 52.9%

DataUtilities.java (Carter and Ayo)
- Instructions: 80.2%
- Branch: 73.5%
- Method: 100%

# 4 A high level description of five selected test cases you have designed using coverage information, and how they have increased code coverage

## __RangeTest.java__

@Test

public void testCombineRangeNull() {


Range range1 = null;
Range range2 = null;

Range testResult = Range.combine(range1, range2);

assertNull(testResult);

}

This test case was designed to increase branch-coverage because we could see that combine in Range had a branch to check for null ranges.

@Test

public void testCentralValue() {

Range range1 = new Range(4, 10);

double testResult = range1.getCentralValue();

assertTrue(testResult == 7);

}

This test case was designed to increase method-coverage to make sure that the output is as expected and that we tested each method in the class.


@Test

public void testIntersectEqual() {

Range range1 = new Range(21, 25);

Range range2 = new Range(21, 21);

boolean testResult = range1.intersects(range2);

assertFalse(testResult);

}

This test case for function Intersect was designed using branch and method coverage information and helped increase coverage for those areas. The functions intersect are overloaded with one taking in two doubles as arguments and another taking in another range object. This test case tests the intersect method that takes in a double as an argument and also tests a branch of the intersect method that has the logic. Since (b0 < this.upper && b1 >= b0) is the condition, this test case tests the branch where b0 < upper and b1 > b0.


@Test(expected = IllegalArgumentException.class)

public void testRangeInvalid() {

Range range1 = new Range(35, 32);

}

This test case is designed to increase branch-coverage because with the ability to see the constructor of a Range object, we see that an IllegalArgumentException is thrown if a range is attempted to be 
constructed with a lower bound higher than upper bound. This test case also increases statement-coverage by making sure we are testing all lines within the constructor.

@Test

public void testCombineIgnoringRange2NaNandRange1NaN() {

Range range1 = new Range(Double.NaN, Double.NaN);

Range range2 = new Range(Double.NaN, Double.NaN);

Range testResult = Range.combineIgnoringNaN(range1, range2);

assertNull(testResult);

}

This test case is designed to increase all method-coverage, branch-coverage, and statement coverage because it tests a branch of the combineIgnoringNaN function with both ranges having NaN values for lower and upper bounds. The combineIgnoringNaN function calls the min and max functions and therefore increase method-coverage and also statement-coverage making sure more of the code is covered and tested.


## __DataUtilitiesTest.java__

### __createNumberArrayOneElement()__

changed to createNumberArrayOneElementPos() and createNumberArrayOneElementNeg()
- Instruction: 13.7% to 23.3%
- Branch: 11% to 19.2%
- Method: 50% to 50%

splitting the create number array test into a positive and negative test was able to incease the coverage of the method. This is important because every possible input must be tested.

### __getCumulativePercentagesWithValueNull()__

changed to getCumulativePercentagesWithValueNullFirst(), getCumulativePercentagesWithValueNullSecond(), and getCumulativePercentagesWithValueNullThird()
- Instruction: 33.7% to 100%
- Branch: 45.8% to 100%
- Method: 100% to 100%

Before all three of these tests were in one try loop so only the first test was being run. Splitting the tests into three different methods was able to increase the coverage of the method to 100%.

### __getCumulativePercentagesTotalNull()__

changed to getCumulativePercentagesTotalNullFirst(), getCumulativePercentagesTotalNullSecond(), and getCumulativePercentagesTotalNullThird()
- Instruction: 40% to 100%
- Branch: 50% to 100%
- Method: 100% to 100%

Similar to the prior example, when the test method was split to have one test per method the coverage was able to be increased to 100%.

# 5 A detailed report of the coverage achieved of each class and method (a screen shot from the code cover results in green and red color would suffice)

RangeTest.java (Maheen and Jason)

DataUtilitiesTest.java (Ayo and Carter)
- Instructions: 95.2%
- Branch: 88.5%
- Method: 100%

__DataUtilites Instruction Coverage__

<img title="DataUtilites Instruction" alt="Alt text" src="Photos/dataInstruction.png">


__DataUtilites Branch Coverage__

<img title="DataUtilites Branch" alt="Alt text" src="Photos/dataBranch.png">


__DataUtilites Method Coverage__

<img title="DataUtilites Method" alt="Alt text" src="Photos/dataMethod.png">


# 6 Pros and Cons of coverage tools used and Metrics you report

Our group primarily used EclEmma as the coverage tool for this lab. We chose this tool over the others provided mainly due to the ease of use and setup, as well the compatibility with Eclipse IDE. We found that it was easy to navigate through the documentation provided, and then be able to swap between different coverage metrics, such as branch, line, and method coverage. The only con to using EclEmma was that there was a slight learning curve to using it, and it took our group some time to be able to use it smoothly.

# 7 A comparison on the advantages and disadvantages of requirements-based test generation and coverage-based test generation.

Creating tests is importent for any project in order to detect any errors in the code. First we look at requirements based testing, this involves creating tests based on the requirements of a project. This is useful because it tests wheter or not the code is working as intended. However, this method is not very effective because it doesn't test the code for all possible inputs, and there may be gaps in the test cases.

Coverage based testing is a method that tests the code based on total coverage. This is useful because you are able to check if the code is working for all possible inputs. The test cases are also more catered to the specific source code. some flaws with coverage based testing is that the tester must understand the code being tested extensively. This can be difficult if the code is complex. Another problem is that critical functions may not be tested extensively enough like in requirements based testing.

# 8 A discussion on how the team work/effort was divided and managed

All of the team work and effort was divided equally among the 4 group members, so that each member was able to do hands-on work in developing the unit tests. We divided the work so that two members worked on data.utilities, and the other two members worked on data.range. After all tests were written, we all met to compare our coverage results, as well as to discuss ways to improve the coverage percentage. Altogether, all group work was evenly divided.

# 9 Any difficulties encountered, challenges overcome, and lessons learned from performing the lab

We experienced difficulties in navigating the different coverage tools provided by the lab. As it was our first time using them, we experienced a significant learning curve in experimenting with the different tools, and understanding the most effective one to use. We overcame these challenges by reading through source documentation and experimenting through trial and error, in order to understand which tool to use.

# 10 Comments/feedback on the lab itself

Altogether, this lab was a great way for us to utilize the concepts regarding code and control flow coverage in a practical learning environment. We now feel comfortable with applying the skills learned from the lab in real world situations.
